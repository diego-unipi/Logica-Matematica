\section{Formule, Strutture e Teorie}
La logica, lo dice il nome si occupa di linguaggi. Un \vocab{linguaggio} è un insieme di \vocab{stringhe},
ossia sequenze finite di simboli, di un certo \vocab{alfabeto}\footnote{Tecnicamente $L = A^{<\NN}$, con $A$ alfabeto.}.
Da un punto di vista tecnico, se vogliamo formalizzare il nostro discorso,
per esempio, nella teoria degli insiemi, potremmo dire che l'alfabeto può essere un insieme qualunque.
Se, per esempio, vogliamo usare come alfabeto $A = \{a,b,c,\ldots,z\}$, dove $a,b,c$, etc. possono essere qualunque, purché distinti fra loro,
allora le stringhe sono sequenze \textcolor{purple}{finite} come, per esempio:
\[ () \qquad (a,x,a,x,a,x,a,x,a,x) \qquad (m,l,\ddot{o})
\]
che conviene scrivere più compattamente come:
\[ \varepsilon\footnote{È la \vocab{stringa vuota}.} \qquad axaxaxaxax \qquad ml\ddot{o}
\]
L'ambiente in cui formalizziamo le nostre definizioni, in questo caso la teoria degli insiemi, si dice \vocab{metateoria}.
Non vogliamo forzare una particolare scelta per la metateoria. Sarà elementare formalizzare il materiale di questo corso, per chi,
per esempio, ha seguito il corso di \href{https://ciovil.li/eti22/}{\textcolor{purple}{Elementi di Teoria degli Insiemi}}, prendendo come 
metateoria la teoria degli insiemi di Zermelo-Fraenkel ($\mathsf{ZFC}$). La nostra esposizione sarà basata su $\mathsf{ZFC}$, mantenendo, però,
un tono informale, con due promesse: di non fare leva sui dettagli incidentali della formalizzazione di $\mathsf{ZFC}$, e di evidenziare i casi in cui
si sfruttano principi insiemistici non costitutivi - in pratica, forme dell'assioma di scelta. \\
In conclusione, parleremo di stringhe che sono sequenze finite di elementi dell'alfabeto, ma mantenendo l'illusione che siano semplicemente tracce di inchiostro sulla carta,
che è, poi, l'intuizione che intendiamo formalizzare. Illusione doppiamente, perché, nella fattispecie, non c'è inchiostro, ma configurazioni di elettricità statica.

\subsection{Formule}
Informalmente, vorremmo generalizzare il meccanismo per mezzo del quale si dice che un \textbf{gruppo} è un insieme dotato di un elemento invertibile \textbf{\textit{e}}, un'operazione $\ldots \cdot \ldots$, etc.
tale che $(x \cdot y) \cdot z = x \cdot (y \cdot z)$, $x \cdot e = e \cdot x = x$, etc. Vorremmo dire che un gruppo è semplicemente un \vocab{modello} della teoria dei gruppi, la quale è costituita dalle condizioni -
l'associatività, l'esistenza dell'identità e degli inversi - che vede soddisfare un \vocab{struttura} per essere un gruppo. Per esplorare matematicamente la relazione che lega una teoria ai suoi modelli, occorre specificare 
precisamente di che tipo siano le condizioni che possono costituire una teoria - per noi saranno le \vocab{formule al primo ordine} - e come una struttura la soddisfa.
L'idea è che una formula si ottenga combinando \vocab{formule atomiche} - per esempio equazioni - per mezzo di connettivi logici: $\land,\lor,\neg,\to$ e i quantificatori $\forall$, $\exists$.

\begin{example}
    [Teoria dei gruppi - v.1]
    \emph{}\vspace{-0.7cm}
    \begin{itemize}
        \item \textbf{simboli di base}: $e,\ldots\cdot\ldots,\ldots^{-1}$
        \item \textbf{assiomi}:
        \begin{align*}
            &\forall x\; \forall y\; \forall z \; (x \cdot y) \cdot z = x \cdot (y \cdot z) \\
            &\forall x\; e \cdot x = x \\
            &\forall x\; x \cdot e = x \\
            &\forall x\; x \cdot (x^{-1}) = e \\
            &\forall x\; (x^{-1}) \cdot x = e
        \end{align*}
    \end{itemize}
    Notare che il dominio dei quantificatori è costituito da tutti gli elementi del gruppo: $\forall x$ significa ``per ogni elemento del gruppo''.
\end{example}

Spesso non c'è un unico modo di formalizzare un concetto.

\begin{example}
    [Teoria dei gruppi - v.2]
    \emph{}\vspace{-0.7cm}
    \begin{itemize}
        \item \textbf{simboli di base}: $e,\ldots\cdot\ldots$
        \item \textbf{assiomi}:
        \begin{align*}
            &\forall x\; \forall y\; \forall z \; (x \cdot y) \cdot z = x \cdot (y \cdot z) \\
            &\forall x\; e \cdot x = x \\
            &\forall x\; x \cdot e = x \\
            &\forall x\; x \cdot (x^{-1}) = e \\
            &\forall x\; \exists y\; x \cdot y = e \land y \cdot x = e
        \end{align*}
    \end{itemize}
\end{example}

\textcolor{purple}{Crucialmente} è ammesso quantificare solo su elementi della struttura, non, per esempio, sui sottoinsiemi. Questo è il motivo per cui si parla di \textbf{logica al primo ordine}.
della struttura, sui numeri naturali o sulle formule stesse. È per questa ragione che la logica che studiamo si dice \vocab{del primo ordine}: se, per esempio, potessimo quantificare anche sui sottoinsiemi
della struttura, allora lavoreremmo al \vocab{secondo ordine}. $\mathsf{ZFC}$, la teoria degli insiemi, ricorderete, è formalizzata al primo ordine - c'è un solo tipo di oggetti, gli insiemi, e si può dire ``per ogni insieme $x$''
o ``esiste un insieme $x$''. Quando, in $\mathsf{ZFC}$, si quantifica sui sottoinsiemi, lo si fa per mezzo di una perifrasi, $\forall x \subseteq y \ldots$ significa $\forall x \; x \subseteq y \to \ldots$, e questo è sottilmente diverso
da dire ``per ogni sottoinsieme $x$ di $y$'', infatti, dire ``per ogni elemento elemento $x$ dell'universo degli insiemi che sia un sottoinsieme di $y$'. Vedremo una conseguenza sorprendente, il \vocab{paradosso di Skolem}, di questo fatto. 
Formalmente, definiremo le formule dando  una grammatica - in particolare una \vocab{grammatica libera dal contesto}.

\medskip

Una grammatica identifica le stringhe di un linguaggio descrivendo un processo ricorsivo che permette di scrivere una stringa più lunga combinando stringhe più brevi.
Lo studio, in generale, delle grammatiche non fa parte degli obiettivi di questo corso, vediamo invece il caso particolare che ci interessa.

\begin{definition}
    [Linguaggio del primo ordine]
    Un \vocab{linguaggio del primo ordine} - brevemente linguaggio - $L = (R,F,\ar)$ è dato da due insiemi disgiunti $R$ e $F$, rispettivamente i \vocab{simboli di relazione} e i \vocab{simboli di funzione}, e una funzione
    $\ar : R \sqcup F \to \NN$ che associa ad ogni simbolo un numero naturale, detto \vocab{arietà}.\footnote{Tecnicamente staremmo anche fissando un alfabeto da cui prendere i simboli.}
\end{definition}

\begin{example}
    [Linguaggio degli anelli ordinati]
    Il linguaggio degli anelli ordinati è:
    \[ L_{or} = (\{<\},\{0,1,+,\cdot\},\ar_{or})
    \]
    dove:
    \begin{align*}
        &\ar_{or}(<) = 2 &&\text{\textcolor{orange}{$<$} è un \underline{simbolo di relazione binaria}} \\
        &\ar_{or}(+) = \ar_{or}(\cdot) = 2 &&\text{\textcolor{orange}{+} e \textcolor{orange}{$\cdot$} sono \underline{simboli di funzione binaria}} \\
        &\ar_{or}(0) = \ar_{or}(1) = 0 &&\text{\textcolor{orange}{0} e \textcolor{orange}{1} sono \underline{simboli di costante}}
    \end{align*}
    Si osservi che i simboli di constante li vediamo come funzioni di arietà 0.
\end{example}

\textcolor{MidnightBlue}{\underline{Nota}: qui c'è un piccolo conflitto nella terminologia, perché, secondo la definizione precedente, un ``linguaggio'' è, in pratica, la collezione dei simboli di base
di una teoria, mentre abbiamo già chiamato ``linguaggio'' l'insieme delle stringhe. È così non è colpa mia.}

\begin{remark}
    Nella definizione di linguaggio ammettiamo simboli di funzione 0-ari, che chiameremo \vocab{simboli di costante}, e simboli di relazione 0-ari, che chiameremo \vocab{simboli di costante proposizionale}.
    Le costanti proposizionali ammetteranno due sole interpretazioni: \emph{vero} e \emph{falso}.
\end{remark}

Per il resto di questo capitolo fissiamo un linguaggio al primo ordine $L = (R,F,\ar)$.

\begin{definition}
    [$L$-termine]
    Gli \vocab{$L$-termini} sono stringhe dell'alfabeto dato da:
    \[ F \sqcup \{\textcolor{purple}{x_0},\textcolor{purple}{x_1},\textcolor{purple}{x_2}, \ldots\} \sqcup \{\textcolor{purple}{(}, \textcolor{purple}{)}, \textcolor{purple}{,}\}
    \]
    Chiamiamo l'insieme numerabile:
    \[ \Var \Mydef \{\textcolor{purple}{x_0},\textcolor{purple}{x_1},\textcolor{purple}{x_2}, \ldots\} = \{\textcolor{purple}{x_i}\}_{i \in \NN}
    \]
    insieme dei \vocab{simboli di variabile}. Un \vocab{$L$-termine} è quindi una stringa in $F \sqcup \Var \sqcup \{\textcolor{purple}{(}, \textcolor{purple}{)}, \textcolor{purple}{,}\}$, e può essere [definito induttivamente come segue]:
    \begin{itemize}
        \item un simbolo di variabile $\textcolor{purple}{x_i} \in \Var$
        \item la stringa $\textcolor{purple}{f(}t_1\textcolor{purple}{,}t_2\textcolor{purple}{,} \ldots\textcolor{purple}{,} t_k\textcolor{purple}{)}$, dove $\textcolor{purple}{f} \in F$ è un simbolo di funzione, $t_1,\ldots,t_k$ sono $L$-termini, e $\ar(f) = k$.
    \end{itemize}
\end{definition}

\begin{remark}
    Se $\textcolor{purple}{c}$ è un simbolo di costante - funzione 0-aria - allora $\textcolor{purple}{c()}$ è un $L$-termine (abbiamo detto che le funzioni $k$-arie valutate in $L$-termini sono a loro volta $L$-termini, dunque $c()$ lo è in automatico).
    In pratica, ometteremo le parentesi, scrivendo semplicemente $\textcolor{purple}{c}$.
    Similmente useremo, per i simboli che denotano le operazioni aritmetiche, la comune \emph{notazione infissa}, per esempio $x_0 + (x_1 \cdot x_2)$ in luogo di $+(x_0, \cdot(x_1,x_2))$.
    Infine ci prenderemo la libertà di usare scritture diverse da $x_0,x_1,x_2$ etc. per i simboli di variabile, es. $x+y\cdot z$, dove non può esserci confusione.
    Non bisogna confondere le scritture di questo tipo $x+y\cdot z$, che sono abbreviazioni, un stereografia che impieghiamo fra di noi per parlare dei termini, con i termini stessi, che sono gli oggetti definiti formalmente.
\end{remark}

\begin{example}
    Ecco alcuni esempi di $L_{or}$ termini:
    \[ \cdot(+(x_0,1()),x_1) \qquad +(+(1(),1()),1())
    \]
    vulgo:
    \[ (x_0 + 1) \cdot x_1 \qquad (1 + 1) + 1
    \]
\end{example}

\begin{definition}
    [$L$-formula]
    Le \vocab{$L$-formule} sono stringhe dell'alfabeto dato da:
    \[ F \sqcup R \sqcup \Var \sqcup \{\textcolor{purple}{(}, \textcolor{purple}{)}, \textcolor{purple}{,}, \textcolor{purple}{\top}, \textcolor{purple}{\bot}, \textcolor{purple}{\neg}, \textcolor{purple}{\land}, \textcolor{purple}{\lor}, \textcolor{purple}{\to}, \textcolor{purple}{\forall}, \textcolor{purple}{\exists}\}\,\footnote{Pertanto
    la differenza sostanziale tra $L$-termini ed $L$-formule sta nel fatto che, nelle seconde, le stringe possono essere costruite ricorsivamente anche usando connettivi logici e quantificatori (ed usando come base anche relazioni di $L$-termini (e non funzioni)).}
    \]
    Una $L$-formula può essere una \vocab{formula atomica}, ossia:
    \begin{itemize}
        \item $\textcolor{purple}{\top}$ o $\textcolor{purple}{\bot}$,
        \item $\textcolor{purple}{r(} t_1\textcolor{purple}{,} t_2\textcolor{purple}{,} \ldots\textcolor{purple}{,} t_k\textcolor{purple}{)}$ con $\textcolor{purple}{r} \in R$ simbolo di relazione e $t_1,\ldots,t_k$ $L$-termini, e $\ar(r) = k$,
        \item $t_1\, \textcolor{purple}{=}\, t_2$ con $t_1,t_2$ $L$-termini. 
    \end{itemize}
    oppure è ottenuta combinando formule atomiche per mezzo di \vocab{connettivi logici} e \vocab{quantificatori}:
    \begin{itemize}
        \item $\textcolor{purple}{(\neg\,} \varphi\textcolor{purple}{)}$ con $\varphi$ $L$-formula,
        \item $\textcolor{purple}{(} \varphi \,\textcolor{purple}{\land}\, \psi\textcolor{purple}{)}$ con $\varphi,\psi$ $L$-formule,
        \item $\textcolor{purple}{(} \varphi \,\textcolor{purple}{\lor}\, \psi\textcolor{purple}{)}$ con $\varphi,\psi$ $L$-formule,
        \item $\textcolor{purple}{(} \varphi \,\textcolor{purple}{\to}\, \psi\textcolor{purple}{)}$ con $\varphi,\psi$ $L$-formule,
        \item $\textcolor{purple}{(\forall x_k} \;\varphi\textcolor{purple}{)}$ con $\varphi$ $L$-formula e $x_k \in \Var$ simbolo di variabile,
        \item $\textcolor{purple}{(\exists x_k} \;\varphi\textcolor{purple}{)}$ con $\varphi$ $L$-formula e $x_k \in \Var$ simbolo di variabile.
    \end{itemize}
\end{definition}

La tecnica più immediata per dimostrare un enunciato a proposito di tutte le formule è l'\vocab{induzione strutturale} o \vocab{induzione sulla complessità delle formule}. Ossia, per dimostrare che tutte le formule godono di una proprietà $\pi$,
si dimostra che $\pi$ vale per le formule atomiche, e che $\pi$ vale per una combinazione a patto che valga per le sue componenti. Similmente si può procedere per induzione sulla complessità dei termini: i casi base sono i simboli di variabile e di costante.
La correttezza di questi procedimenti è immediata osservando che si possono giustificare con una semplice induzione aritmetica sulla lunghezza delle formule.

\begin{remark}
    I casi nelle definizioni di $L$-formula e $L$-termine sono disgiunti, ossia, data una $L$-formula, o un $L$-termine, questo oggetto ricade necessariamente in uno e un solo dei casi della sua definizione.
\end{remark}

Questa osservazione ci permette di procedere non solo per induzione, ma anche per \vocab{ricorsione strutturale}, ossia definire una funzione delle formule descrivendo come il valore associato da $f$ a una combinazione
dipende solo da $f$ e dalle sue componenti. Vediamo qualche esempio.

\begin{definition}
    [Sottoformula]
    Le \vocab{sottoformule} di una formula $\varphi$ sono:
    \begin{itemize}
        \item $\varphi$ stessa
    \end{itemize}
    inoltre:
    \begin{itemize}
        \item se $\varphi = \textcolor{purple}{(\neg}\, \psi \textcolor{purple}{)}$, allora tra le sottoformule di $\varphi$ ci sono anche le sottoformule di $\psi$,
        \item se $\varphi = \textcolor{purple}{(} \psi_1 \,\textcolor{purple}{\land} \,\psi_2 \textcolor{purple}{)}$ o $\varphi = \textcolor{purple}{(} \psi_1\, \textcolor{purple}{\lor}\, \psi_2 \textcolor{purple}{)}$ o
        $\varphi = \textcolor{purple}{(} \psi_1\, \textcolor{purple}{\to} \,\psi_2 \textcolor{purple}{)}$, allora tra le sottoformule di $\varphi$ ci sono anche le sottoformule di $\psi_1$ e $\psi_2$,
        \item se $\varphi = \textcolor{purple}{(\forall x_k} \,\psi \textcolor{purple}{)}$ o $\varphi = \textcolor{purple}{(\exists x_k}\, \psi \textcolor{purple}{)}$, allora tra le sottoformule di $\varphi$ ci sono anche le sottoformule di $\psi$.
    \end{itemize}
\end{definition}

Nella definizione precedente abbiamo definito le sottoformule per via ricorsiva - ossia, abbiamo definito le sottoformule di una formula $\varphi$ in termini delle sottoformule delle componenti di $\varphi$ (oltre a $\varphi$ stessa).

\begin{definition}
    [Variabili libere di una formula]
    Definiamo prima le \vocab{variabili libere di un termine}. Dato un $L$-termine $t$ definiamo $\textcolor{purple}{\var(} t \textcolor{purple}{)}$ dicendo che:
    \begin{itemize}
        \item se $t = \textcolor{purple}{x_i} \in \Var$, allora $\var(t) = \{\textcolor{purple}{x_i}\}$,
        \item se $t = \textcolor{purple}{f(}t_1\textcolor{purple}{,} \ldots\textcolor{purple}{,} t_k\textcolor{purple}{)}$, allora $\var(t) = \bigcup_{i = 1}^k \var(t_k)$.
    \end{itemize}
    Adesso che abbiamo definito ricorsivamente le variabili libere di un $L$-termine $t$, possiamo definire le \vocab{variabili libere di una $L$-formula} $\varphi$, $\textcolor{purple}{\vl(} \varphi \textcolor{purple}{)}$ come segue per le formule atomiche:
    \begin{itemize}
        \item se $\varphi = \textcolor{purple}{\top}$ o $\varphi = \textcolor{purple}{\bot}$, allora $\vl(\varphi) = \emptyset$,
        \item se $\varphi = \textcolor{purple}{r(} t_1\textcolor{purple}{,} \ldots\textcolor{purple}{,} t_k\textcolor{purple}{)}$, allora $\vl(\varphi) = \bigcup_{i = 1}^k \var(t_k)$,
        \item se $\varphi = t_1\, \textcolor{purple}{=}\, t_2$, allora $\vl(\varphi) = \var(t_1) \cup \var(t_2)$.
    \end{itemize}
    e per le formule composte:
    \begin{itemize}
        \item se $\varphi = \textcolor{purple}{(\neg}\, \psi \textcolor{purple}{)}$, allora $\vl(\varphi) = \vl(\psi)$,
        \item se $\varphi = \textcolor{purple}{(} \psi_1 \,\textcolor{purple}{\land} \,\psi_2 \textcolor{purple}{)}$ o $\varphi = \textcolor{purple}{(} \psi_1\, \textcolor{purple}{\lor}\, \psi_2 \textcolor{purple}{)}$ o $\varphi = \textcolor{purple}{(} \psi_1\, \textcolor{purple}{\to} \,\psi_2 \textcolor{purple}{)}$, allora $\vl(\varphi) = \vl(\psi_1) \cup \vl(\psi_2)$,
        \item se $\varphi = \textcolor{purple}{(\forall x_k} \,\psi \textcolor{purple}{)}$ o $\varphi = \textcolor{purple}{(\exists x_k}\, \psi \textcolor{purple}{)}$, allora $\vl(\varphi) = \vl(\psi) \setminus \{\textcolor{purple}{x_k}\}$.
    \end{itemize}
\end{definition}

\begin{remark}
    [Variabili legate]
    L'ultimo caso è cruciale: nelle formule $\textcolor{purple}{\forall x_k} \, \psi$ e $\textcolor{purple}{\exists x_k} \, \psi$ la variabile $\textcolor{purple}{x_k}$ non è libera, è \vocab{legata} dal quantificatore.
    Si noti che non è richiesto che $\textcolor{purple}{x_k}$ compaia fra le variabili libere di $\phi$ [Possibile typo di Mamino $\psi$?].
\end{remark}

\begin{example}
    Vediamo alcuni esempi:
    \begin{itemize}[$\diamondsuit$]
        \item $\vl(\exists x_1 \; x_0 = x_1 \cdot x_1) = \{x_0\}$ e la variabile $x_1$ è legata.
        \item $\vl((\exists x_1 \; x_0 = x_1 \cdot x_1) \land (\exists x_0 \; x_1 = x_0 \cdot x_0) = \{x_0\} \cup \{x_1\} = \{x_0,x_1\}$\footnote{Se interpretassimo queste due affermazioni nei naturali, la prima vorrebbe dire ogni numero è un quadrato, mentre la seconda che ogni numero naturale ha un quadrato.}.
        \item $\vl((\forall x_7 \; (\exists x_7 \; x_2 + x_2 = x_4))) = \{x_2,x_4\}$, si noti che il $\forall$ all'inizio è uno specchietto per le allodole, in quanto non conta nulla per il significato della formula.
    \end{itemize}
\end{example}

\begin{exercise}
    [Per chi conosce $\mathsf{ZF}$]
    Dimostrare dettagliatamente in $\mathsf{ZF}$ che la ricorsione strutturale è un procedimento corretto.
\end{exercise}

\begin{note}
    Le definizioni date in questa sezione hanno lo scopo di trasformare gli enunciati matematici in oggetti matematici essi stessi: le formule.
    Questa sezione serve per descrivere formalmente i nostri oggetti di studio e \textcolor{purple}{non ha un intento normativo}\footnote{Non stiamo dicendo come 
    la matematica dovrebbe essere fatta/scritta, stiamo constatando che viene fatta/scritta in certi modi, e stiamo formalizzando precisamente cosa sono questi modi.}.
    In particolare, a patto di non causare ambiguità, scriviamo le formule in modo abbreviato in ogni situazione pratica. Così ad esempio:
    \begin{align*}
        &\forall x\; \exists y \; y \cdot y \cdot y = x + y &&\text{al posto di  $\forall x_0(\exists x_1 \; x_1 \cdot x_1 \cdot x_1 = x_0 + x_1)$} \\
        &\forall x\; 0 < x \to \exists y \; x = y \cdot y &&\text{al posto di $\forall x_0(0 < x_0 \to \exists x_1 \; x_0 = x_1 \cdot x_1)$}
    \end{align*}
\end{note}

\subsection{Cosa significano le formule}
Definiamo in questa sezione un concetto di \vocab{struttura} che generalizza le familiari strutture algebriche - gruppi, anelli, ordini, etc.
Diremo quindi cosa significa che una struttura soddisfa una formula. Questo ci permetterà di precisare la nozione di \vocab{conseguenza logica}:
$\psi$ è conseguenza logica di $\varphi$ se ogni struttura che soddisfa $\varphi$ soddisfa anche $\psi$. Grazie alla nozione di conseguenza logica, potremo parlare 
di \vocab{teorie} e dei loro \vocab{modelli} - per esempio i gruppi saranno i modelli della teoria dei gruppi.
Insomma, daremo una \vocab{semantica} per la logica del primo ordine, ossia una risposta lla domanda ``cosa significano le formule?''.

\begin{definition}
    [$L$-struttura]
    Fissato un linguaggio al primo ordine $L = (R,F,\ar)$, diciamo che una \vocab{$L$-struttura} $M = (D;i)$ è il dato di un insieme $D$ non vuoto, detto 
    \vocab{dominio} della struttura, e di una funzione $i$, che chiameremo \vocab{interpretazione dei simboli}, avente come dominio $F \sqcup R$ (il nostro alfabeto) e tale che:
    \begin{align*}
        &\forall r \in  R \quad i(r) \subseteq D^{\ar(r)} \\
        &\forall f \in F \quad i(f) : D^{\ar(f)} \to D
    \end{align*}
    ossia un simbolo di relazione $n$-aria è interpretato come un sottoinsieme di $D^n$, e un simbolo di funzione $n$-aria come una funzione da $D^n$ a $D$.
\end{definition}

\begin{note}
    In molti casi, è chiaro dal contesto quali siano le arietà e le interpretazioni dei simboli di un certo linguaggio. Per esempio, se parliamo della struttura
    $(\ZZ, \textcolor{purple}{0}, \textcolor{purple}+,\textcolor{purple}-, \textcolor{purple}\cdot, \textcolor{purple}<)$ è chiaro che ci riferiamo alla struttura che ha per dominio $\ZZ$,
    nel linguaggio $L = (R,F)$ con $R = \{\textcolor{purple}{<}\}$ e $F = \{\textcolor{purple}0, \textcolor{purple}+,\textcolor{purple}-, \textcolor{purple}\cdot\}$, con:
    \[ \ar(\textcolor{purple}<) = 2 \qquad \ar(\textcolor{purple}+) = \ar(\textcolor{purple}\cdot) = 2 \qquad \ar(\textcolor{purple}-) = 1 \qquad \ar(\textcolor{purple}0) = 0
    \]
    con:
    \begin{align*}
        &i(\textcolor{purple}<) = \{ (x,y) \in \ZZ^2 \mid x < y \} \subseteq \ZZ^2 = D^{\ar(\textcolor{purple}<)} \\
        &i(\textcolor{purple}0) : D^{\ar(\textcolor{purple}0)} = \{\bullet\} \in \ZZ = D \qquad i(\textcolor{purple}0)(\bullet) = 0\\
        &i(\textcolor{purple}-) : D^{\ar(\textcolor{purple}-)} = \ZZ \to \ZZ \qquad i(\textcolor{purple}-)(n) = -n \\
        &i(\textcolor{purple}+) : D^{\ar(\textcolor{purple}+)} = \ZZ^2 \to \ZZ \qquad i(\textcolor{purple}+)(n,m) = n+m \\
        &i(\textcolor{purple}\cdot) : D^{\ar(\textcolor{purple}\cdot)} = \ZZ^2 \to \ZZ \qquad i(\textcolor{purple}\cdot)(n,m) = n \cdot m
    \end{align*}
    Non c'è dubbio che conviene scrivere $(\ZZ; \textcolor{purple}0, \textcolor{purple}+,\textcolor{purple}-, \textcolor{purple}\cdot, \textcolor{purple}<)$, e non ci si confonde.
    Detta $M$ questa struttura, in luogo, per esempio, di $i(\textcolor{purple}+)$, scriveremo semplicemente $+_M$ o anche solo $+$, così $i(\textcolor{purple}+)(2,3) = 2 +_M 3 = 2+3$.
\end{note}

Per il resto di questa sezione fissiamo una $L$-struttura $M = (D;i)$. Vogliamo dire quando una formula $\varphi$ è \vocab{valida} nella struttura $M$, o, equivalentemente, $M$ \vocab{soddisfa} $\varphi$,
in simboli $M \models \varphi$. Per poter formulare la definizione per ricorsione strutturale, occorre generalizzare il concetto introducendo un \vocab{ambiente} o \vocab{valutazione delle variabili} $v$.
Così, per esempio, $M \models \{v\} \; \textcolor{purple}{x = y}$ se e solo se l'ambiente $v$ dà a $\textcolor{purple}{x}$ e $\textcolor{purple}{y}$ il medesimo valore.

\begin{definition}
    [Valutazione delle variabili]
    \vocab{Valutazione delle variabili} è un modo poetico per dire funzione da $\Var$ a $D$.
\end{definition}

\begin{notation}
    Data una valutazione delle variabili $v$ e un $a \in D$, indichiamo con $v[a/x_n]$ la valutazione:
    \[ v[a/x_n](x_i)\begin{cases}
        v(x_i) &\text{se $i \neq n$} \\
        a &\text{se $i = n$}
    \end{cases}
    \]
    Con $v[a_1/x_{n_1},\ldots,a_k/x_{n_k}]$ indichiamo $v[a_1/x_{n_1}]\ldots[a_k/x_{n_k}]$.
\end{notation}

\begin{definition}
    [Semantica di Tarski]
    Ricordiamo che è fissato un linguaggio al primo ordine $L$ ed una $L$-struttura $M$. Fissiamo anche un ambiente $v$.
    In questo contesto possiamo definire per ricorsione strutturale l'\vocab{interpretazione} di una $L$-formula, partendo dagli $L$-termini come segue:
    \[ \begin{aligned}
        \{v\}_M \, \textcolor{purple}{x_k} &\Mydef v(\textcolor{purple}{x_k}) \\
        \{v\}_M \, \textcolor{purple}{f}\textcolor{purple}{(} t_1\textcolor{purple}{,} \ldots\textcolor{purple}{,} t_k \textcolor{purple}{)} &\Mydef i(\textcolor{purple}{f})\left(\{v\}_M \, t_1, \ldots, \{v\}_M \, t_k\right) \qquad \text{con $\textcolor{purple}{f} \in F$}
    \end{aligned} \]
    La relazione di \vocab{soddisfacibilità} $M \models \{v\}\varphi$ (ometteremo $M$ al pedice d'ora in poi) per una formula $\varphi$ nella struttura $M$ e nell'ambiente $v$ è definita ricorsivamente per le formule atomiche da:
    \begin{align*}
        &M \models \{v\} \textcolor{purple}{\,\top} \qquad \neg M \models \{v\} \textcolor{purple}{\,\bot} \\
        &M \models \{v\} \textcolor{purple}{\,r(} t_1\textcolor{purple}{,} \ldots\textcolor{purple}{,} t_k \textcolor{purple}{)} \overset{\text{def}}{\iff} \left(\{v\}_M \, t_1, \ldots, \{v\}_M \, t_k\right) \in i(\textcolor{purple}{r}) =: r_M \\
        &M \models \{v\} \textcolor{purple}{\,t_1 = t_2} \overset{\text{def}}{\iff} \{v\}_M \, t_1 = \{v\}_M \, t_2
    \end{align*}
    ed infine la soddisfacibilità per le $L$-formule composte è definita come segue:
    \begin{align*}
        &M \models \{v\} \textcolor{purple}{(\neg}\, \psi \textcolor{purple}{)} &&\overset{\text{def}}{\iff} \neg M \models \{v\} \psi \\
        &M \models \{v\} \textcolor{purple}{(} \psi_1 \,\textcolor{purple}{\land} \,\psi_2 \textcolor{purple}{)} &&\overset{\text{def}}{\iff} M \models \{v\} \psi_1 \land M \models \{v\} \psi_2 \\
        &M \models \{v\} \textcolor{purple}{(} \psi_1\, \textcolor{purple}{\lor}\, \psi_2 \textcolor{purple}{)} &&\overset{\text{def}}{\iff} M \models \{v\} \psi_1 \lor M \models \{v\} \psi_2 \\
        &M \models \{v\} \textcolor{purple}{(} \psi_1\, \textcolor{purple}{\to} \,\psi_2 \textcolor{purple}{)} &&\overset{\text{def}}{\iff} M \models \{v\} \psi_1 \to M \models \{v\} \psi_2 \\
        &M \models \{v\} \textcolor{purple}{(\forall x_k} \,\psi \textcolor{purple}{)} &&\overset{\text{def}}{\iff} \forall a \in D \quad M \models \{v[a/\textcolor{purple}{x_k}]\} \psi \\
        &M \models \{v\} \textcolor{purple}{(\exists x_k}\, \psi \textcolor{purple}{)} &&\overset{\text{def}}{\iff} \exists a \in D \quad M \models \{v[a/\textcolor{purple}{x_k}]\} \psi
    \end{align*}
\end{definition}

\begin{example}
    Sia $(M;\textcolor{purple}p)$, dove $\textcolor{purple}p$ è un simbolo di relazione unaria. Cosa significa, secondo la semantica di Tarski, che $M \models \{v\}\,\textcolor{purple}{\exists x(p(x) \to \forall y \; p(y))}$?
\end{example}

\begin{soln}
    Intuitivamente, ci aspettiamo che asserire che $M$ soddisfa quella formula equivalga, nella metateoria, alla proposizione $\exists a \in D(a \in p_M \to \forall b \in D \; b \in p_M)$.
    Vediamo come questo segue formalmente dalla semantica di Tarski.
    \begin{align*}
        & M \models \{v\} \textcolor{purple}{(\exists x(p(x) \to \forall y \; p(y))} \\
        & \exists a \in D \; M \models \{v[a/\textcolor{purple}{x}]\} \textcolor{purple}{(p(x) \to \forall y \; p(y))} \\
        & \exists a \in D \; M \models \{v[a/\textcolor{purple}{x}]\} \textcolor{purple}{p(x)} \to M \models \{v[a/\textcolor{purple}{x}]\} \textcolor{purple}{\forall y \; p(y)} \\
        & \exists a \in D \; \{v[a/\textcolor{purple}{x}]\}_M \textcolor{purple}{p(x)} \to \forall b \in D \; M \models \{v[a/\textcolor{purple}{x},b/\textcolor{purple}{y}]\} \textcolor{purple}{p(y)} \\
        & \exists a \in D \; \{v[a/\textcolor{purple}{x}]\}_M \textcolor{purple}{p(x)} \to \forall b \in D \; \{v[a/\textcolor{purple}{x},b/\textcolor{purple}{y}]\}_M \textcolor{purple}{p(y)} \\
        & \exists a \in D \; a \in p_M \to \forall b \in D \; b \in p_M
    \end{align*}
\end{soln}